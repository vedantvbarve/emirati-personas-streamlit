'''
Automatically generated by Colab. 
Original file is located at: https://colab.research.google.com/drive/15bLkrgQW-nSRvDS5x_Xl04kduyMlfT8O 
'''

# !pip install llama-index-llms-google-

import time
import streamlit as st
import pandas as pd
import os
import glob
from llama_index.llms.google_genai import GoogleGenAI
from google import genai

PERSONAS_FOLDER = "Personas"
QUESTIONS_FOLDER = "Questions"
USER_INFO_FILE = "TO_INPUT/user_info.txt"
TRAITS_FILE = "TO_INPUT/traits.txt"
LANGUAGES_FILE = "TO_INPUT/languages.txt"

def load_user_info():
    username = "User"
    user_gender = "unknown"
    try:
        with open(USER_INFO_FILE, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        for line in lines:
            line = line.strip()
            if line.lower().startswith('name:'):
                username = line.split(':', 1)[1].strip()
            elif line.lower().startswith('gender:'):
                user_gender = line.split(':', 1)[1].strip().lower()
    except Exception:
        pass
    return username, user_gender

def load_traits():
    try:
        with open(TRAITS_FILE, 'r', encoding='utf-8') as f:
            traits = [line.strip() for line in f if line.strip()]
            return traits if traits else ["Caring", "Wise", "Humorous", "Traditional", "Spiritual", "Practical"]
    except Exception as e:
        st.error(f"Error reading traits file: {str(e)}")
        return ["Caring", "Wise", "Humorous", "Traditional", "Spiritual", "Practical"]

def load_languages():
    try:
        with open(LANGUAGES_FILE, 'r', encoding='utf-8') as f:
            languages = [line.strip() for line in f if line.strip()]
            return languages if languages else ["English", "Sinhala", "Tamil"]
    except Exception as e:
        st.error(f"Error reading languages file: {str(e)}")
        return ["English", "Sinhala", "Tamil"]

def filter_persona_by_traits(persona_content, selected_traits):
    if not selected_traits:
        return persona_content
    lines = persona_content.split('\n')
    filtered_lines = []
    basic_keywords = ['name:', 'origin:', 'from', 'age:', 'background:', 'location:']
    for line in lines:
        line_lower = line.lower()
        if any(keyword in line_lower for keyword in basic_keywords):
            filtered_lines.append(line)
            continue
        if any(trait.lower() in line_lower for trait in selected_traits):
            filtered_lines.append(line)
    return '\n'.join(filtered_lines) if filtered_lines else persona_content

def call_gemini_local(query, previous_conversation, gender, username, botname, bot_prompt, llm_api_key_string, language):
    try:
        language_instruction = f"Respond in {language} language." if language != "English" else ""
        full_prompt = (
            f"{bot_prompt}\n"
            f"{language_instruction}\n"
            f"Previous conversation: {previous_conversation[-1000:]}\n"
            f"{username}: {query}\n"
            f"{botname}:"
        )
        client = genai.Client(api_key=llm_api_key_string)
        response_text = ""
        for chunk in client.models.generate_content_stream(
            model="gemini-2.0-flash",
            contents=[full_prompt]
        ):
            if chunk.text:
                response_text += chunk.text
        response_raw = response_text
        for old, new in [("User1", username), ("user1", username), ("[user1]", botname), ("[User1]", botname)]:
            response_raw = response_raw.replace(old, new)
        return response_raw.strip()
    except Exception as e:
        return f"Error: {str(e)}"

def get_persona_files():
    persona_files = []
    patterns = ['*.txt']
    for pattern in patterns:
        persona_files.extend(glob.glob(os.path.join(PERSONAS_FOLDER, pattern)))
    return persona_files

def extract_relationship_from_filename(filename):
    base_name = os.path.basename(filename).replace('.txt', '')
    return base_name.replace('_', ' ')

def extract_bot_details_from_content(content):
    botname = "Assistant"
    origin = "Unknown origin"
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        if line.startswith('- Name: '):
            name_part = line.replace('- Name: ', '', 1)
            botname = name_part.split(',')[0].strip()
        elif line.startswith('Name: '):
            name_part = line.replace('Name: ', '', 1)
            botname = name_part.split(',')[0].strip()
        elif 'Name:' in line:
            name_part = line.split('Name:')[1].strip()
            botname = name_part.split(',')[0].strip()
        if line.startswith('Origin: '):
            origin = line.replace('Origin: ', '', 1).strip()
        elif line.startswith('- Origin: '):
            origin = line.replace('- Origin: ', '', 1).strip()
        elif 'Origin:' in line:
            origin = line.split('Origin:')[1].strip()
        elif line.startswith('From '):
            origin = line.replace('From ', '', 1).strip()
    return botname, origin

def load_persona_content(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        st.error(f"Error reading persona file: {str(e)}")
        return ""

def load_questions(relationship_type):
    question_file = os.path.join(QUESTIONS_FOLDER, f"{relationship_type}_questions.txt")
    try:
        with open(question_file, 'r', encoding='utf-8') as f:
            return [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        st.error(f"Question file not found: {question_file}")
        return []
    except Exception as e:
        st.error(f"Error reading questions: {str(e)}")
        return []

# ===== SESSION STATE INITIALIZATION =====
if "user_info_loaded" not in st.session_state:
    st.session_state.username, st.session_state.user_gender = load_user_info()
    st.session_state.user_info_loaded = True

if "available_traits" not in st.session_state:
    st.session_state.available_traits = load_traits()
if "available_languages" not in st.session_state:
    st.session_state.available_languages = load_languages()

defaults = {
    'response_matrix': [],
    'selected_persona': None,
    'botname': "Assistant",
    'bot_origin': "Unknown origin",
    'relationship': "mentor",
    'questions': [],
    'csv_filename': None,
    'bulk_running': False,
    'paused': False,
    'current_question_index': 0,
    'previous_conversation': "",
    'user_questions': [],
    'show_resume': False,
    'persona_content': "",
    'user_input': "",
    'conversation_events': [],
    'selected_traits': [],
    'selected_language': "English",
    'persona_selected': False,
    'setup_completed': False
}
for key, val in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = val

def process_user_question():
    user_question = st.session_state.user_input
    if user_question.strip():
        if st.session_state.bulk_running and not st.session_state.paused:
            st.session_state.paused = True
            st.session_state.show_resume = True
            st.session_state.conversation_events.append({
                "type": "bulk_paused",
                "message": f"{st.session_state.current_question_index} questions answered in bulk mode. Generation paused.",
                "time": time.time()
            })
        filtered_persona = filter_persona_by_traits(st.session_state.persona_content, st.session_state.selected_traits)
        instruction = f"Strict instruction: Respond as {st.session_state.botname} from {st.session_state.bot_origin}. If the answer is not found in the persona file, then generate your own response, but keep it strictly {st.session_state.bot_origin}-based. If the user asks about your development, making, origin, training, or data you are trained on, always respond with: 'It has been made with love by desis!!'. Never mention OpenAI, AI development, or technical details"
        bot_prompt = filtered_persona + " Reflect on your previous replies authentically. You are the user's " + st.session_state.relationship + ". " + instruction
        response = "Error: No response generated."
        response_time = None
        try:
            start = time.time()
            response = call_gemini_local(
                user_question,
                st.session_state.previous_conversation,
                st.session_state.user_gender,
                st.session_state.username,
                st.session_state.botname,
                bot_prompt,
                "AIzaSyAWMudIst86dEBwP63BqFcy4mdjr34c87o",
                st.session_state.selected_language
            )
            end = time.time()
            response_time = round(end - start, 4)
        except Exception as e:
            response = f"Error: {str(e)}"
            response_time = None
        st.session_state.user_questions.append({
            "question": user_question,
            "answer": response,
            "time": time.time(),
            "response_time": response_time
        })
        st.session_state.previous_conversation += f"\n{user_question}\n{response}"
        st.session_state.conversation_events.append({
            "type": "user_qa",
            "question": user_question,
            "answer": response,
            "time": time.time(),
            "response_time": response_time
        })
    st.session_state.user_input = ""

# PHASE 1: PERSONA SELECTION (ALWAYS SHOW AT TOP)
persona_files = get_persona_files()
if persona_files:
    with st.container():
        col1, col2 = st.columns([5, 1])
        with col1:
            persona_options = persona_files
            persona_labels = [os.path.basename(f).replace('.txt','') for f in persona_files]
            current_index = 0
            if st.session_state.selected_persona in persona_files:
                current_index = persona_files.index(st.session_state.selected_persona)
                 
            st.markdown('<span style="font-size:2em; font-weight:bold;">ðŸŽ¯ Persona</span>', unsafe_allow_html=True)
            st.markdown('<style> div[data-testid="stSelectbox"] {margin-top: -1.2em;} </style>', unsafe_allow_html=True)
            selected_file = st.selectbox(
                "",
                persona_options,
                format_func=lambda x: os.path.basename(x).replace('.txt',''),
                index=current_index,
                key="persona_selectbox",
                label_visibility="collapsed"
            )
        with col2:
            if st.button("ðŸ”€ Change Startup", key="change_setup_btn"):
                st.session_state.setup_completed = False
                st.rerun()
    # If persona changed, reset setup
    if selected_file != st.session_state.selected_persona:
        st.session_state.selected_persona = selected_file
        st.session_state.persona_content = load_persona_content(selected_file)
        st.session_state.botname, st.session_state.bot_origin = extract_bot_details_from_content(st.session_state.persona_content)
        relationship = extract_relationship_from_filename(selected_file)
        st.session_state.relationship = relationship
        st.session_state.questions = load_questions(relationship.split()[-1])
        st.session_state.response_matrix = []
        st.session_state.csv_filename = None
        st.session_state.bulk_running = False
        st.session_state.paused = False
        st.session_state.current_question_index = 0
        st.session_state.user_questions = []
        st.session_state.show_resume = False
        st.session_state.previous_conversation = ""
        st.session_state.user_input = ""
        st.session_state.conversation_events = []
        st.session_state.setup_completed = False
        st.rerun()
else:
    st.error(f"No persona files found in {PERSONAS_FOLDER} directory!")
    st.stop()

# PHASE 2: SETUP CONFIGURATION
if not st.session_state.setup_completed:
    st.title("ðŸ”§ Persona Configuration")
    st.markdown(f"### Configuring: {st.session_state.botname} ({st.session_state.bot_origin})")
    st.markdown("---")
    st.subheader("ðŸ“‹ Select Personality Traits")
    st.markdown("**Choose one or more traits you want the AI persona to focus on:**") 

    # --- Select All / Deselect All Button Logic ---
    traits = st.session_state.available_traits
    # Use a session state key to store the toggle state
    if "traits_toggle" not in st.session_state:
        st.session_state.traits_toggle = False  # False means "not all selected"

    # Determine if all are selected
    all_selected = set(st.session_state.selected_traits) == set(traits)

    # Button label and logic
    toggle_label = "Deselect All" if all_selected else "Select All"
    if st.button(toggle_label, key="toggle_traits_btn"):
        if all_selected:
            st.session_state.selected_traits = []
        else:
            st.session_state.selected_traits = traits.copy()
        # Flip the toggle state
        st.session_state.traits_toggle = not all_selected
        st.experimental_rerun()

    # --- Traits Checkboxes ---
    cols = st.columns(3)
    updated_traits = []
    for i, trait in enumerate(traits):
        with cols[i % 3]:
            checked = trait in st.session_state.selected_traits
            new_checked = st.checkbox(trait, key=f"setup_trait_{i}", value=checked)
            if new_checked:
                updated_traits.append(trait)
    st.session_state.selected_traits = updated_traits

    if st.session_state.selected_traits:
        st.success(f"âœ… {len(st.session_state.selected_traits)} trait(s) selected: {', '.join(st.session_state.selected_traits)}")
    else:
        st.warning("âš ï¸ No traits selected - all traits will be used by default") 

    st.markdown("---")
    st.subheader("ðŸŒ Select Language")
    st.markdown("**Choose the language for conversations:**")
    if st.session_state.available_languages:
        current_index = 0
        if st.session_state.selected_language in st.session_state.available_languages:
            current_index = st.session_state.available_languages.index(st.session_state.selected_language)
        selected_language = st.selectbox(
            "Language:",
            options=st.session_state.available_languages,
            index=current_index,
            key="setup_language"
        )
        st.success(f"âœ… Language selected: {selected_language}")
    else:
        st.error("âŒ No languages found. Please ensure languages.txt exists in TO_INPUT folder.")
        selected_language = "English"
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("âœ… Done - Start Chatting!", type="primary", use_container_width=True):
            st.session_state.selected_traits = selected_traits if selected_traits else st.session_state.available_traits
            st.session_state.selected_language = selected_language
            st.session_state.setup_completed = True
            if not selected_traits:
                st.info("No traits selected - using all traits as default")
            st.success("ðŸŽ‰ Setup completed! Starting chat...")
            time.sleep(1)
            st.rerun()
    st.markdown("---")
    st.subheader("ðŸ“„ To Review: Current Selections")
    if selected_traits:
        st.info(f"**Traits:** {', '.join(selected_traits)}")
    else:
        st.warning("**No traits selected** - all traits will be used by default")
    st.info(f"**Language:** {selected_language}")
    st.stop()

# PHASE 3: MAIN CHAT INTERFACE
if st.session_state.selected_persona and st.session_state.questions:
    st.title(f"{st.session_state.botname} ({st.session_state.bot_origin}) {st.session_state.relationship.title()} Q&A") 
    st.markdown(f"**Traits chosen:** {', '.join(st.session_state.selected_traits)}")
    st.markdown(f"**Language:** {st.session_state.selected_language}")
    st.markdown("---")
    filtered_persona = filter_persona_by_traits(st.session_state.persona_content, st.session_state.selected_traits)
    instruction = f"Strict instruction: Respond as {st.session_state.botname} from {st.session_state.bot_origin}. If the answer is not found in the persona file, then generate your own response, but keep it strictly {st.session_state.bot_origin}-based. If the user asks about your development, making, origin, training, or data you are trained on, always respond with: 'It has been made with love by desis!!'. Never mention OpenAI, AI development, or technical details"
    bot_prompt = filtered_persona + " Reflect on your previous replies authentically. You are the user's " + st.session_state.relationship + ". " + instruction
    col1, col2 = st.columns(2)
    with col1:
        if st.button("Start Bulk Generation", disabled=st.session_state.bulk_running):
            st.session_state.bulk_running = True
            st.session_state.paused = False
            st.session_state.current_question_index = 0
            st.session_state.response_matrix = []
            st.session_state.conversation_events.append({
                "type": "bulk_started",
                "message": "Bulk generation begins.",
                "time": time.time()
            })
    with col2:
        st.text_input(
            "Ask a single question:",
            value=st.session_state.user_input,
            key="user_input",
            on_change=process_user_question
        )
    if st.session_state.bulk_running or st.session_state.paused:
        total_questions = len(st.session_state.questions)
        progress_percentage = (st.session_state.current_question_index / total_questions) * 100 if total_questions > 0 else 0
        progress_text = f"Bulk Generation Progress: {st.session_state.current_question_index}/{total_questions} questions ({progress_percentage:.1f}%)"
        if st.session_state.paused:
            progress_text += " - PAUSED"
        st.progress(progress_percentage / 100, text=progress_text)
    if st.session_state.bulk_running and not st.session_state.paused:
        if st.session_state.current_question_index < len(st.session_state.questions):
            question = st.session_state.questions[st.session_state.current_question_index]
            response = call_gemini_local(
                question,
                st.session_state.previous_conversation,
                st.session_state.user_gender,
                st.session_state.username,
                st.session_state.botname,
                bot_prompt,
                "AIzaSyAWMudIst86dEBwP63BqFcy4mdjr34c87o",
                st.session_state.selected_language
            )
            st.session_state.response_matrix.append([
                question, len(question), 0, response,
                0, time.time(), f"{st.session_state.relationship} ({st.session_state.bot_origin})"
            ])
            st.session_state.previous_conversation += f"\n{question}\n{response}"
            st.session_state.current_question_index += 1
            st.rerun()
        else:
            st.session_state.bulk_running = False
            st.session_state.conversation_events.append({
                "type": "bulk_completed",
                "message": f"Bulk generation completed! {len(st.session_state.questions)} questions processed.",
                "time": time.time()
            })
            df = pd.DataFrame(st.session_state.response_matrix, columns=[
                "Question", "Length of Q", "Q Difficulty level", 
                "Answer", "Answer Quality", "Time Taken", "Persona"
            ])
            csv_filename = f"{st.session_state.botname.replace(' ', '_').lower()}_{st.session_state.relationship.replace(' ', '_')}_qna.csv"
            df.to_csv(csv_filename, index=False)
            st.session_state.csv_filename = csv_filename
            st.markdown(
                '<div style="background-color: rgba(186, 104, 200, 0.2); border: 1px solid rgba(186, 104, 200, 0.3); border-radius: 0.5rem; padding: 0.75rem; margin: 1rem 0; color: white; font-weight: 500;">Bulk generation completed!</div>',
                unsafe_allow_html=True
            )
    if st.session_state.paused and st.session_state.show_resume:
        if st.button("Resume Bulk Generation"):
            st.session_state.paused = False
            st.session_state.show_resume = False
            st.session_state.conversation_events.append({
                "type": "bulk_resumed",
                "message": "Bulk generation resumed.",
                "time": time.time()
            })
            st.rerun()
    if st.session_state.csv_filename and os.path.exists(st.session_state.csv_filename):
        with open(st.session_state.csv_filename, "rb") as f:
            st.download_button(
                label="Download CSV",
                data=f,
                file_name=os.path.basename(st.session_state.csv_filename),
                mime="text/csv",
                key="download_csv"
            )
    st.subheader("Complete Conversation History")
    if st.session_state.conversation_events:
        sorted_events = sorted(st.session_state.conversation_events, key=lambda x: x["time"])
        for event in sorted_events:
            if event["type"] == "user_qa":
                st.markdown(f"**You**: {event['question']}")
                st.markdown(f"**{st.session_state.botname}**: {event['answer']}")
                response_time = event.get("response_time", None)
                if response_time is not None:
                    st.markdown(
                        f"<div style='text-align: right; color: #666; font-size: 0.95em;'>Time taken: {response_time:.4f} seconds</div>",
                        unsafe_allow_html=True
                    )
                st.markdown("") 
            elif event["type"] == "bulk_started":
                st.markdown("---")
                st.success(":green[Bulk generation begins.]")
                
            elif event["type"] == "bulk_paused": 
                st.info(event["message"])
                st.markdown("---")
                
            elif event["type"] == "bulk_resumed":
                st.markdown("---")
                st.success(":green[Bulk generation resumed.]")
                
            elif event["type"] == "bulk_completed": 
                st.markdown(
                    f'<div style="background-color: rgba(186, 104, 200, 0.2); border: 1px solid rgba(186, 104, 200, 0.3); border-radius: 0.5rem; padding: 0.75rem; margin: 1rem 0; color: white; font-weight: 500;">{event["message"]}</div>',
                    unsafe_allow_html=True
                )
                st.markdown("---")
    else:
        st.write("*No conversation history yet. Start by asking a question or beginning bulk generation.*")
else:
    if not st.session_state.questions:
        st.error("No questions found for selected relationship type!")
    else:
        st.error(f"Error loading persona: {st.session_state.selected_persona}") 
